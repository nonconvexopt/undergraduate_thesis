{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image\n",
    "import pdb\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flows import PlanarFlow\n",
    "from utils import Binarize\n",
    "import codes\n",
    "\n",
    "from torchmeta.datasets.helpers import cifar_fs\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "\n",
    "#from __future__ import print_function\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "cur_dir = \"C:/Users/KJH/OneDrive - skku.edu/KJH/Projects/2019winter_research\"\n",
    "#cur_dir = \"C:/Users/KJH-Laptop/OneDrive - skku.edu/KJH/Projects/2019winter_research/\"\n",
    "os.chdir(cur_dir)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random as rd\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Normalize training set together with augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "])\n",
    "\n",
    "# Normalize test set same as training set without augmentation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "])\n",
    "\n",
    "batch_size_train = 128\n",
    "batch_size_test = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10('./data/CIFAR10/',\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size_train, shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10('./data/CIFAR10/',\n",
    "                                        train=False,\n",
    "                                        download=True,\n",
    "                                        transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size_test, shuffle=False, num_workers=8)\n",
    "\n",
    "class Conv2d_flipout(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=False, padding_mode='zeros'):\n",
    "        super(Conv2d_flipout, self).__init__(\n",
    "                 in_channels = in_channels, out_channels = out_channels, kernel_size = kernel_size, stride = stride,\n",
    "                 padding = padding, dilation = dilation, groups = groups, bias = bias, padding_mode = padding_mode)\n",
    "        \n",
    "        self.weight_mean = nn.Parameter(torch.empty(self.weight.data.shape, device = device).normal_(0,1))\n",
    "        weight_prec_prior = torch.distributions.gamma.Gamma(torch.ones(self.weight.data.shape), torch.ones(self.weight.data.shape))\n",
    "        self.weight_logvar = nn.Parameter(weight_prec_prior.sample().reciprocal().log().to(device))\n",
    "        \n",
    "        self.kld = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.weight.data = torch.empty(self.weight.data.shape, device = device).normal_(0,1) * self.weight_logvar.div(2).exp() + self.weight_mean\n",
    "        x = torch.empty(x.shape, device = device, requires_grad = False).uniform_(-1,1).sign() * x\n",
    "        self.kld = torch.sum(self.weight_mean**2 -self.weight_logvar +self.weight_logvar.exp() -1)/2 / x.shape[0]\n",
    "        return self.conv2d_forward(x, self.weight)\n",
    "\n",
    "\n",
    "\n",
    "class Linear_flipout(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(Linear_flipout, self).__init__()\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight_mean = nn.Parameter(torch.empty([self.in_features, self.out_features], device = device).normal_(0,1))\n",
    "        weight_prec_prior = torch.distributions.gamma.Gamma(torch.ones(self.weight_mean.data.shape)/2, torch.ones(self.weight_mean.data.shape)/2)\n",
    "        self.weight_logvar = nn.Parameter(weight_prec_prior.sample().reciprocal().log().to(device))\n",
    "        \n",
    "        self.kld = None\n",
    "        \n",
    "        self.bias = bias\n",
    "        if bias:\n",
    "            self.bias_mean = nn.Parameter(torch.empty(self.out_features, device = device).normal_(0,1))\n",
    "            bias_prec_prior = torch.distributions.gamma.Gamma(torch.ones(self.bias_mean.data.shape)/2, torch.ones(self.bias_mean.data.shape)/2)\n",
    "            self.bias_logvar = nn.Parameter(bias_prec_prior.sample().reciprocal().log().to(device))\n",
    "        else:\n",
    "            self.bias_mean = None\n",
    "            self.bias_logvar = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        weight_noise = torch.empty(self.weight_mean.data.shape, device = device).normal_(0,1)\n",
    "        \n",
    "        output = torch.mm(x, self.weight_mean)\n",
    "\n",
    "        in_sign = torch.empty(x.shape, device = device, requires_grad = False).uniform_(-1,1).sign()\n",
    "        out_sign = torch.empty([x.shape[0], self.out_features], device = device, requires_grad = False).uniform_(-1,1).sign()\n",
    "        output += torch.mm(in_sign * x, weight_noise * self.weight_mean * self.weight_logvar.div(2).exp()) * out_sign\n",
    "        \n",
    "        self.kld = torch.sum(self.weight_mean**2 -self.weight_logvar +self.weight_logvar.exp() -1) /2 / x.shape[0]   \n",
    "        \n",
    "        if self.bias:\n",
    "            bias_noise = torch.empty(self.bias_mean.data.shape, device = device).normal_(0,1)\n",
    "            output += (1 + bias_noise * self.bias_logvar.div(2).exp()) * self.bias_mean\n",
    "            self.bias_mean.grad = (1 + bias_noise * self.bias_logvar.div(2).exp())\n",
    "            self.bias_logvar.grad = (self.bias_mean * bias_noise).div(2) * self.bias_logvar.div(2).exp()\n",
    "            \n",
    "            self.kld += torch.sum(self.bias_mean**2 -self.bias_logvar + self.bias_logvar.exp() -1)/2 / x.shape[0]\n",
    "            \n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(pred, label, model, progress):\n",
    "    loss = F.cross_entropy(pred, label, weight=None, ignore_index=-100, reduction='mean')\n",
    "    if progress < 0.5:\n",
    "        loss += (2 * progress)**2 * model.kld()\n",
    "    else:\n",
    "        loss += model.kld()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.8994],\n",
      "        [-0.1946]], device='cuda:0', requires_grad=True)\n",
      "tensor([[1.0562],\n",
      "        [1.8276]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "Parameter containing:\n",
      "tensor([-1.1346], device='cuda:0', requires_grad=True)\n",
      "tensor([112.5163], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "None\n",
      "tensor(6.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(2.3252, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.9517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0258, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0199, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0168, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0157, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0153, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0150, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0147, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0146, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0145, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0143, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0140, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0134, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor(0.0135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 1.1617],\n",
      "        [-2.9853]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0114],\n",
      "        [0.0093]], device='cuda:0', grad_fn=<ExpBackward>)\n",
      "Parameter containing:\n",
      "tensor([-0.6352], device='cuda:0', requires_grad=True)\n",
      "tensor([0.9135], device='cuda:0', grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "reg = Linear_flipout(2, 1, bias = True).cuda()\n",
    "#reg = nn.Linear(2,1).cuda()\n",
    "x = torch.empty(1000, 2, device = device).normal_(0,1)\n",
    "y = (torch.empty(1, device = device).normal_(2,0.7) * x[:,0:1]\n",
    "     + torch.empty(1, device = device).normal_(-3,0.3) * x[:,1:]\n",
    "     + torch.empty(1000, 1, device = device).normal_(0,1) + 1)\n",
    "\n",
    "#opt = optim.SGD(reg.parameters(), lr=3e-4, momentum=0.9, weight_decay=5e-4)\n",
    "opt = optim.Adam(reg.parameters(), lr=1)\n",
    "\n",
    "print(reg.weight_mean)\n",
    "print(reg.weight_logvar.div(2).exp())\n",
    "print(reg.bias_mean)\n",
    "print(reg.bias_logvar.div(2).exp())\n",
    "print(reg.kld)\n",
    "\n",
    "for rep in range(500):\n",
    "    opt.zero_grad()\n",
    "    loss = ((y - reg(x))**2).sum() + reg.kld\n",
    "    loss.backward()\n",
    "    #reg.backward()\n",
    "    #print(reg.weight.grad)\n",
    "    #print(loss.detach())\n",
    "    \n",
    "    opt.step()\n",
    "    print(reg.kld)\n",
    "\n",
    "print(reg.weight_mean)\n",
    "print(reg.weight_logvar.div(2).exp())\n",
    "print(reg.bias_mean)\n",
    "print(reg.bias_logvar.div(2).exp())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_idx(N):\n",
    "    # generate the indeces of the N context points in a flattened image\n",
    "    idx = random.sample(range(0, 784), N)\n",
    "    idx = torch.tensor(idx, device=device)\n",
    "    return idx\n",
    "\n",
    "\n",
    "def generate_grid(h, w):\n",
    "    rows = torch.linspace(0, 1, h, device=device)\n",
    "    cols = torch.linspace(0, 1, w, device=device)\n",
    "    grid = torch.stack([cols.repeat(h, 1).t().contiguous().view(-1), rows.repeat(w)], dim=1)\n",
    "    grid = grid.unsqueeze(0)\n",
    "    return grid\n",
    "\n",
    "\n",
    "def idx_to_y(idx, data):\n",
    "    # get the [0;1] pixel intensity at each index\n",
    "    y = torch.index_select(data, dim=1, index=idx)\n",
    "    return y\n",
    "\n",
    "\n",
    "def idx_to_x(idx, batch_size):\n",
    "    # From flat idx to 2d coordinates of the 28x28 grid. E.g. 35 -> (1, 7)\n",
    "    # Equivalent to np.unravel_index()\n",
    "    x = torch.index_select(x_grid, dim=1, index=idx)\n",
    "    x = x.expand(batch_size, -1, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "class NP(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(NP, self).__init__()\n",
    "        self.r_dim = args.r_dim\n",
    "        self.z_dim = args.z_dim\n",
    "\n",
    "        self.h_1 = nn.Linear(3, 400)\n",
    "        self.h_2 = nn.Linear(400, 400)\n",
    "        self.h_3 = nn.Linear(400, self.r_dim)\n",
    "\n",
    "        self.r_to_z_mean = nn.Linear(self.r_dim, self.z_dim)\n",
    "        self.r_to_z_logvar = nn.Linear(self.r_dim, self.z_dim)\n",
    "\n",
    "        self.g_1 = nn.Linear(self.z_dim + 2, 400)\n",
    "        self.g_2 = nn.Linear(400, 400)\n",
    "        self.g_3 = nn.Linear(400, 400)\n",
    "        self.g_4 = nn.Linear(400, 400)\n",
    "        self.g_5 = nn.Linear(400, 1)\n",
    "\n",
    "    def h(self, x_y):\n",
    "        x_y = F.relu(self.h_1(x_y))\n",
    "        x_y = F.relu(self.h_2(x_y))\n",
    "        x_y = F.relu(self.h_3(x_y))\n",
    "        return x_y\n",
    "\n",
    "    def aggregate(self, r):\n",
    "        return torch.mean(r, dim=1)\n",
    "\n",
    "    def reparameterise(self, z):\n",
    "        mu, logvar = z\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z_sample = eps.mul(std).add_(mu)\n",
    "        z_sample = z_sample.unsqueeze(1).expand(-1, 784, -1)\n",
    "        return z_sample\n",
    "\n",
    "    def g(self, z_sample, x_target):\n",
    "        z_x = torch.cat([z_sample, x_target], dim=2)\n",
    "        input = F.relu(self.g_1(z_x))\n",
    "        input = F.relu(self.g_2(input))\n",
    "        input = F.relu(self.g_3(input))\n",
    "        input = F.relu(self.g_4(input))\n",
    "        y_hat = torch.sigmoid(self.g_5(input))\n",
    "        return y_hat\n",
    "\n",
    "    def xy_to_z_params(self, x, y):\n",
    "        x_y = torch.cat([x, y], dim=2)\n",
    "        r_i = self.h(x_y)\n",
    "        r = self.aggregate(r_i)\n",
    "\n",
    "        mu = self.r_to_z_mean(r)\n",
    "        logvar = self.r_to_z_logvar(r)\n",
    "\n",
    "        return mu, logvar\n",
    "\n",
    "    def forward(self, x_context, y_context, x_all=None, y_all=None):\n",
    "        z_context = self.xy_to_z_params(x_context, y_context)  # (mu, logvar) of z\n",
    "        if self.training:  # loss function will try to keep z_context close to z_all\n",
    "            z_all = self.xy_to_z_params(x_all, y_all)\n",
    "        else:  # at test time we don't have the image so we use only the context\n",
    "            z_all = z_context\n",
    "\n",
    "        z_sample = self.reparameterise(z_all)\n",
    "\n",
    "        # reconstruct the whole image including the provided context points\n",
    "        x_target = x_grid.expand(y_context.shape[0], -1, -1)\n",
    "        y_hat = self.g(z_sample, x_target)\n",
    "\n",
    "        return y_hat, z_all, z_context\n",
    "\n",
    "\n",
    "def kl_div_gaussians(mu_q, logvar_q, mu_p, logvar_p):\n",
    "    var_p = torch.exp(logvar_p)\n",
    "    kl_div = (torch.exp(logvar_q) + (mu_q - mu_p) ** 2) / var_p \\\n",
    "             - 1.0 \\\n",
    "             + logvar_p - logvar_q\n",
    "    kl_div = 0.5 * kl_div.sum()\n",
    "    return kl_div\n",
    "\n",
    "\n",
    "def np_loss(y_hat, y, z_all, z_context):\n",
    "    BCE = F.binary_cross_entropy(y_hat, y, reduction=\"sum\")\n",
    "    KLD = kl_div_gaussians(z_all[0], z_all[1], z_context[0], z_context[1])\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "model = NP(args).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "x_grid = generate_grid(28, 28)\n",
    "os.makedirs(\"results/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "epoch : 0, train loss = 2.357553, acc = 0.102, reg = 91.5498, time: 124.659379 sec\n",
      "epoch : 1, train loss = 2.366360, acc = 0.108, reg = 81.0944, time: 123.171208 sec\n",
      "epoch : 2, train loss = 2.381727, acc = 0.097, reg = 70.5443, time: 121.357049 sec\n",
      "epoch : 3, train loss = 2.401616, acc = 0.100, reg = 61.5948, time: 120.932984 sec\n",
      "epoch : 4, train loss = 2.426486, acc = 0.102, reg = 54.0632, time: 121.403174 sec\n"
     ]
    }
   ],
   "source": [
    "model = \n",
    "epoch = 200\n",
    "lr = 3e-4\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#0.1 for epoch [0,150)\n",
    "#0.01 for epoch [150,250)\n",
    "#0.001 for epoch [250,350)\n",
    "\n",
    "running_test_loss = 0.0\n",
    "for run in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    #Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for ind, data in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        img, label = data\n",
    "        pred = model(img.cuda())\n",
    "        loss = loss_fn(pred, label.cuda(), model, run/epoch)\n",
    "        train_loss += loss.detach() * img.shape[0] \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(trainset)\n",
    "    \n",
    "    #Test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        acc = 0.0\n",
    "        sum_kl = 0\n",
    "        for ind, data in enumerate(testloader):\n",
    "            img, label = data\n",
    "            pred = model(img.cuda())\n",
    "            sum_kl += model.kld().detach()\n",
    "            #test_loss += loss_fn(pred, label.cuda(), model).detach() * img.shape[0]\n",
    "            acc += sum(pred.argmax(1) == label.cuda()).item()\n",
    "        test_loss /= len(testset)\n",
    "        acc /= len(testset)\n",
    "        running_test_loss += test_loss\n",
    "    #print(\"epoch : %d, train loss = %5.6f, test loss = %5.6f, running_test_loss = %5.6f, acc = %.3f, reg = %.4f, time: %f sec\"\n",
    "    #      %(run, train_loss, test_loss, running_test_loss / (run + 1), acc, sum_kl/(ind + 1), time.time() - start))\n",
    "    print(\"epoch : %d, train loss = %5.6f, acc = %.3f, reg = %.4f, time: %f sec\"\n",
    "          %(run, train_loss, acc, sum_kl/(ind + 1), time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

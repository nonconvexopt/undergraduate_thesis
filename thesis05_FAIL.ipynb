{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/thesis03')\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flows import PlanarFlow\n",
    "from utils import Binarize\n",
    "from codes import Linear_flipout, Flatten, count_parameters, EfficientNet\n",
    "\n",
    "from torchmeta.datasets import Omniglot, CIFARFS\n",
    "from torchmeta.transforms import Categorical, ClassSplitter, Rotation\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "\n",
    "#from __future__ import print_function\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "cur_dir = \"C:/Users/KJH/OneDrive - skku.edu/KJH/Projects/2019winter_research\"\n",
    "#cur_dir = \"C:/Users/KJH-Laptop/OneDrive - skku.edu/KJH/Projects/2019winter_research/\"\n",
    "os.chdir(cur_dir)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random as rd\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(net, self).__init__()\n",
    "        self.input_dim = [1, 28, 28]\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.ctx = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n",
    "        self.ctx.conv_stem = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.ctx.classifier = nn.Identity()\n",
    "        \n",
    "        self.layer = nn.LSTM(input_size=1280, hidden_size=1280, num_layers=5, bias=True, batch_first = True, dropout=0.1).to(device)\n",
    "        self.dec_mu = nn.ModuleList()\n",
    "        self.dec_logvar = nn.ModuleList()\n",
    "        \n",
    "        self.num_params = [[200 * 200, 200], [200 * 200, 200], [200 * self.num_classes, self.num_classes]]\n",
    "        \n",
    "        for layer_size in self.num_params:\n",
    "            self.dec_mu.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, 1280, bias = True),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, layer_size[0] + layer_size[1], bias = True),\n",
    "                ).to(device))\n",
    "            \n",
    "            self.dec_logvar.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, 1280, bias = True),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, layer_size[0] + layer_size[1], bias = True),\n",
    "                ).to(device))\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            Flatten(),            \n",
    "            nn.Linear(784, 200, bias = False),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "            \n",
    "            \n",
    "    def forward(self, x_train, label_train, x_test, label_test):\n",
    "        ctx = self.ctx(x_train).view(x_train.shape[0], self.num_classes, 256)\n",
    "        h = torch.stack([ctx[torch.where(label_train == x)].mean(dim = 0) for x in range(self.num_classes)], dim = 1)\n",
    "        h = h.view(self.num_classes, 1, -1)\n",
    "        \n",
    "        kld = torch.tensor(0., device=device)\n",
    "        c = torch.empty([5, 1, 1280], device = device).fill_(0)\n",
    "        x_test = self.encoder(x_test)\n",
    "        for ind, (dec_mu, dec_logvar) in enumerate(zip(self.dec_mu, self.dec_logvar)):\n",
    "            x = torch.empty([1, 1, 1280], device = device).normal_(0, 1)\n",
    "            f, (h, c) = self.layer(x, (h, c))\n",
    "            \n",
    "            mu = dec_mu(f.view(1, -1)).squeeze()\n",
    "            weight_mu = mu[:self.num_params[ind][0]].view(-1, self.num_params[ind][1])\n",
    "            bias_mu = mu[self.num_params[ind][0]:]\n",
    "            \n",
    "            logvar = dec_logvar(f.view(1, -1)).squeeze()\n",
    "            weight_logvar = logvar[:self.num_params[ind][0]].view(-1, self.num_params[ind][1])\n",
    "            bias_logvar = logvar[self.num_params[ind][0]:]\n",
    "            \n",
    "            weight_noise = torch.empty(weight_mu.shape, device = device).normal_(0,1)\n",
    "            bias_noise = torch.empty(bias_mu.shape, device = device).normal_(0,1)\n",
    "            in_sign = torch.empty(x_test.shape,  device = device).uniform_(-1,1).sign()\n",
    "            out_sign = torch.empty([x_test.shape[0], self.num_params[ind][1]], device = device).uniform_(-1,1).sign()\n",
    "        \n",
    "            x_test = torch.mm(x_test, weight_mu) + torch.mm(in_sign * x_test, weight_noise * weight_mu * weight_logvar.div(2).exp()) * out_sign\n",
    "            x_test += (1 + bias_noise * bias_logvar.div(2).exp()) * bias_mu\n",
    "            x_test = F.elu(x_test)\n",
    "            \n",
    "            kld += (mu.pow(2) - logvar + logvar.exp() - 1).sum()/2\n",
    "\n",
    "        return x_test, kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\KJH/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss = 1.610310, kld = 51.537239, acc = 0.211667, time = 8.523 sec\n",
      "  1) loss = 1.610501, kld = 50.743500, acc = 0.205000, time = 7.817 sec\n",
      "  2) loss = 1.609502, kld = 50.179344, acc = 0.196667, time = 7.987 sec\n",
      "  3) loss = 1.609560, kld = 49.956116, acc = 0.208333, time = 7.995 sec\n",
      "  4) loss = 1.609526, kld = 50.229992, acc = 0.219167, time = 11.104 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "meta_trainset = Omniglot('./data/',\n",
    "                   # Number of ways\n",
    "                   num_classes_per_task=5,\n",
    "                   # Resize the images to 28x28 and converts them to PyTorch tensors (from Torchvision)\n",
    "                   transform=Compose([Resize(28), ToTensor()]),\n",
    "                   # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "                   target_transform=Categorical(num_classes=5),\n",
    "                   # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "                   class_augmentations=[Rotation([90, 180, 270])],\n",
    "                   meta_train=True,\n",
    "                   download=True)\n",
    "meta_trainset = ClassSplitter(meta_trainset, shuffle=True, num_train_per_class=1, num_test_per_class=15)\n",
    "meta_trainloader = BatchMetaDataLoader(meta_trainset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "model = net(5).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_batches = 200\n",
    "for batch_idx, meta_train_batch in zip(range(num_batches), meta_trainloader):\n",
    "    start = time.time()\n",
    "\n",
    "    train_inputs, train_targets = [x.to(device) for x in meta_train_batch[\"train\"]]\n",
    "    test_inputs, test_targets = [x.to(device) for x in meta_train_batch[\"test\"]]\n",
    "    \n",
    "    cum_loss = torch.tensor(0., device=device)\n",
    "    accuracy = torch.tensor(0., device=device)\n",
    "    reg = torch.tensor(0., device=device)\n",
    "\n",
    "    for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "        zip(train_inputs, train_targets, test_inputs, test_targets)):\n",
    "        optimizer.zero_grad()\n",
    "        pred, kld = model(train_input, train_target, test_input, test_target)\n",
    "        loss = criterion(pred, test_target)\n",
    "        (loss + 0.1 * kld).backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            pred, kld = model(train_input, train_target, test_input, test_target)\n",
    "            loss = criterion(pred, test_target)\n",
    "            cum_loss += loss\n",
    "            accuracy += torch.sum(pred.argmax(1) == test_target.cuda())\n",
    "            reg += kld\n",
    "    cum_loss /= batch_size\n",
    "    accuracy /= batch_size * 75\n",
    "    reg /= batch_size\n",
    "\n",
    "    writer.add_scalar('train/accuracy', accuracy, batch_idx)\n",
    "    writer.add_scalar('train/reg', reg, batch_idx)\n",
    "    #if batch_idx % 10 == 0:\n",
    "    print(\"%3d) loss = %f, kld = %f, acc = %f, time = %.3f sec\" %(batch_idx, cum_loss, reg, accuracy, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.107535, test_kld = 1.019025, meta_test_acc = 0.014507, time = 2.943 sec\n"
     ]
    }
   ],
   "source": [
    "meta_testset  = Omniglot('./data/',\n",
    "                   # Number of ways\n",
    "                   num_classes_per_task=5,\n",
    "                   # Resize the images to 28x28 and converts them to PyTorch tensors (from Torchvision)\n",
    "                   transform=Compose([Resize(28), ToTensor()]),\n",
    "                   # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "                   target_transform=Categorical(num_classes=5),\n",
    "                   # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "                   class_augmentations=[Rotation([90, 180, 270])],\n",
    "                   meta_train=True,\n",
    "                   download=True)\n",
    "meta_testset = ClassSplitter(meta_testset, shuffle=True, num_train_per_class=5, num_test_per_class=15)\n",
    "meta_testloader = BatchMetaDataLoader(meta_testset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "tot_loss = torch.tensor(0., device=device)\n",
    "tot_acc = torch.tensor(0., device=device)\n",
    "tot_reg = torch.tensor(0., device=device)\n",
    "\n",
    "for batch_idx, meta_test_batch in zip(range(num_batches), meta_testloader):\n",
    "    start = time.time()\n",
    "    train_inputs, train_targets = [x.to(device) for x in meta_test_batch[\"train\"]]\n",
    "    test_inputs, test_targets = [x.to(device) for x in meta_test_batch[\"test\"]]\n",
    "    \n",
    "    cum_loss = torch.tensor(0., device=device)\n",
    "    accuracy = torch.tensor(0., device=device)\n",
    "    reg = torch.tensor(0., device=device)\n",
    "\n",
    "    for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "        zip(train_inputs, train_targets, test_inputs, test_targets)):\n",
    "        with torch.no_grad():\n",
    "            pred, kld = model(train_input, train_target, test_input)\n",
    "            loss = criterion(pred, test_target)\n",
    "            cum_loss += loss\n",
    "            accuracy += torch.sum(pred.argmax(1) == test_target.cuda())\n",
    "            reg += kld\n",
    "\n",
    "    tot_loss += cum_loss\n",
    "    tot_acc += accuracy\n",
    "    tot_reg += reg\n",
    "        \n",
    "tot_loss /= num_batches\n",
    "tot_acc /= num_batches\n",
    "tot_reg /= num_batches\n",
    "        \n",
    "print(\"loss = %f, test_kld = %f, meta_test_acc = %f, time = %.3f sec\" %(tot_loss, tot_reg, tot_acc, time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

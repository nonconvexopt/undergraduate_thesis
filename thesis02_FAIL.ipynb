{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torchvision import models\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/thesis02')\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from flows import PlanarFlow\n",
    "from utils import Binarize\n",
    "from codes import Linear_flipout, Flatten, count_parameters, EfficientNet\n",
    "\n",
    "\n",
    "from torchmeta.datasets import Omniglot, CIFARFS\n",
    "from torchmeta.transforms import Categorical, ClassSplitter, Rotation\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "\n",
    "\n",
    "#from __future__ import print_function\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "cur_dir = \"C:/Users/KJH/OneDrive - skku.edu/KJH/Projects/2019winter_research\"\n",
    "#cur_dir = \"C:/Users/KJH-Laptop/OneDrive - skku.edu/KJH/Projects/2019winter_research/\"\n",
    "os.chdir(cur_dir)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random as rd\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class bnn(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(bnn, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.encoder = nn.Sequential(\n",
    "            Flatten(),\n",
    "\n",
    "            nn.Linear(784, 256, bias = False),\n",
    "            nn.ELU()\n",
    "        ) \n",
    "        self.l0 = nn.Sequential(\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256)\n",
    "        )\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, 256)\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(256, self.num_classes)\n",
    "        )\n",
    "        self.num_hiddens = [\n",
    "            [256],\n",
    "            [256],\n",
    "            [256]\n",
    "        ]\n",
    "\n",
    "    def sample_noise(self, noise):\n",
    "        return torch.sigmoid(noise[0] + noise[1] * torch.empty(noise[0].data.shape, device = device).normal_(0, 1))\n",
    "            \n",
    "    def forward(self, x, noise):            \n",
    "        x = self.encoder(x)\n",
    "        x = self.l0(x * self.sample_noise(noise[0]))\n",
    "        x = self.l1(x * self.sample_noise(noise[1]))\n",
    "        x = self.l2(x * self.sample_noise(noise[2]))\n",
    "        return x\n",
    "    \n",
    "    def noise_grad(self):\n",
    "        grads = []\n",
    "        for layer in self.noise:\n",
    "            grads.append([layer[0].grad, layer[1].grad])\n",
    "        return torch.stack([torch.stack(x, dim = 0) for x in grads], dim = 0)\n",
    "    \n",
    "    \n",
    "class sampler_net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(sampler_net, self).__init__()\n",
    "        self.input_dim = [1, 28, 28]\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.ctx = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'efficientnet_b0', pretrained=True)\n",
    "        self.ctx.conv_stem = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        self.ctx.classifier = nn.Identity()\n",
    "        \n",
    "        self.layer = nn.LSTM(input_size=1280, hidden_size=1280, num_layers=5, bias=True, batch_first = True).to(device)\n",
    "        self.dec_mu = nn.ModuleList()\n",
    "        self.dec_logvar = nn.ModuleList()\n",
    "        \n",
    "        self.sample_net = bnn(self.num_classes)\n",
    "        self.num_params = self.sample_net.num_hiddens\n",
    "        \n",
    "        for layer_size in self.num_params:\n",
    "            self.dec_mu.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, 256, bias = True),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(256, 256, bias = True),\n",
    "                ).to(device))\n",
    "            \n",
    "            self.dec_logvar.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(1280, 256, bias = True),\n",
    "                    nn.ELU(),\n",
    "                    nn.Linear(256, 256, bias = True),\n",
    "                ).to(device))\n",
    "            \n",
    "            \n",
    "    def forward(self, x_train, label_train, x_test):\n",
    "        x = x_train\n",
    "        ctx = self.ctx(x).view(x.shape[0], self.num_classes, 256)\n",
    "        h = torch.stack([ctx[torch.where(label_train == x)].mean(dim = 0) for x in range(self.num_classes)], dim = 1)\n",
    "        h = h.view(self.num_classes, 1, -1)\n",
    "\n",
    "        out = []\n",
    "        kld = torch.tensor(0., device=device)\n",
    "        c = torch.empty([5, 1, 1280], requires_grad = False, device = device).fill_(0)\n",
    "        for dec_mu, dec_logvar in zip(self.dec_mu, self.dec_logvar):\n",
    "            x = torch.empty([1, 1, 1280], requires_grad = False, device = device).normal_(0, 1)\n",
    "            f, (h, c) = self.layer(x, (h, c))\n",
    "            mu = dec_mu(f.view(1, -1)).squeeze()\n",
    "            logvar = dec_logvar(f.view(1, -1)).squeeze()\n",
    "            out.append([mu, logvar])\n",
    "            kld += (mu.pow(2) - logvar + logvar.exp() - 1).mean()/2\n",
    "        return self.sample_net(x_test, out), kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\KJH/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) loss = 1.609909, kld = 0.003760, acc = 0.200000, time = 7.805 sec\n",
      "  1) loss = 1.609633, kld = 0.003787, acc = 0.200000, time = 7.566 sec\n",
      "  2) loss = 1.609422, kld = 0.003775, acc = 0.201667, time = 7.586 sec\n",
      "  3) loss = 1.609432, kld = 0.003788, acc = 0.198333, time = 7.674 sec\n",
      "  4) loss = 1.609439, kld = 0.003747, acc = 0.195833, time = 7.703 sec\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "meta_trainset = Omniglot('./data/',\n",
    "                   # Number of ways\n",
    "                   num_classes_per_task=5,\n",
    "                   # Resize the images to 28x28 and converts them to PyTorch tensors (from Torchvision)\n",
    "                   transform=Compose([Resize(28), ToTensor()]),\n",
    "                   # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "                   target_transform=Categorical(num_classes=5),\n",
    "                   # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "                   class_augmentations=[Rotation([90, 180, 270])],\n",
    "                   meta_train=True,\n",
    "                   download=True)\n",
    "meta_trainset = ClassSplitter(meta_trainset, shuffle=True, num_train_per_class=1, num_test_per_class=15)\n",
    "meta_trainloader = BatchMetaDataLoader(meta_trainset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "model = sampler_net(5).cuda()\n",
    "sample_optimizer = optim.SGD(list(model.sample_net.parameters()), lr = 0.1)\n",
    "optimizer = optim.Adam(list(model.sample_net.parameters()) +\n",
    "                       list(model.ctx.parameters()) +\n",
    "                       list(model.layer.parameters())\n",
    "                      , lr=1e-10)\n",
    "\n",
    "num_batches = 200\n",
    "for batch_idx, meta_train_batch in zip(range(num_batches), meta_trainloader):\n",
    "    start = time.time()\n",
    "\n",
    "    train_inputs, train_targets = [x.to(device) for x in meta_train_batch[\"train\"]]\n",
    "    test_inputs, test_targets = [x.to(device) for x in meta_train_batch[\"test\"]]\n",
    "    \n",
    "    cum_loss = torch.tensor(0., device=device)\n",
    "    accuracy = torch.tensor(0., device=device)\n",
    "    reg = torch.tensor(0., device=device)\n",
    "\n",
    "    for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "        zip(train_inputs, train_targets, test_inputs, test_targets)):\n",
    "        for i in range(1):\n",
    "            sample_optimizer.zero_grad()\n",
    "            pred, kld = model(train_input, train_target, test_input)\n",
    "            loss = F.cross_entropy(pred, test_target)\n",
    "            loss.backward()\n",
    "            sample_optimizer.step()\n",
    "            for param_group in sample_optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.99\n",
    "        optimizer.zero_grad()\n",
    "        pred, kld = model(train_input, train_target, test_input)\n",
    "        loss = F.cross_entropy(pred, test_target)\n",
    "        (loss + kld).backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            cum_loss += loss\n",
    "            accuracy += torch.sum(pred.argmax(1) == test_target.cuda())\n",
    "            reg += kld\n",
    "        \n",
    "    cum_loss /= batch_size\n",
    "    accuracy /= batch_size * 75\n",
    "    reg /= batch_size\n",
    "\n",
    "    writer.add_scalar('train/accuracy', accuracy, batch_idx)\n",
    "    writer.add_scalar('train/reg', reg, batch_idx)\n",
    "    #if batch_idx % 10 == 0:\n",
    "    print(\"%3d) loss = %f, kld = %f, acc = %f, time = %.3f sec\" %(batch_idx, cum_loss, reg, accuracy, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.741117, test_kld = 0.003300, meta_test_acc = 0.876667, time = 4.163 sec\n"
     ]
    }
   ],
   "source": [
    "meta_testset  = Omniglot('./data/',\n",
    "                   # Number of ways\n",
    "                   num_classes_per_task=5,\n",
    "                   # Resize the images to 28x28 and converts them to PyTorch tensors (from Torchvision)\n",
    "                   transform=Compose([Resize(28), ToTensor()]),\n",
    "                   # Transform the labels to integers (e.g. (\"Glagolitic/character01\", \"Sanskrit/character14\", ...) to (0, 1, ...))\n",
    "                   target_transform=Categorical(num_classes=5),\n",
    "                   # Creates new virtual classes with rotated versions of the images (from Santoro et al., 2016)\n",
    "                   class_augmentations=[Rotation([90, 180, 270])],\n",
    "                   meta_train=True,\n",
    "                   download=True)\n",
    "meta_testset = ClassSplitter(meta_testset, shuffle=True, num_train_per_class=5, num_test_per_class=15)\n",
    "meta_testloader = BatchMetaDataLoader(meta_testset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "tot_loss = torch.tensor(0., device=device)\n",
    "tot_acc = torch.tensor(0., device=device)\n",
    "tot_reg = torch.tensor(0., device=device)\n",
    "\n",
    "for batch_idx, meta_test_batch in zip(range(num_batches), meta_testloader):\n",
    "    start = time.time()\n",
    "    train_inputs, train_targets = [x.to(device) for x in meta_test_batch[\"train\"]]\n",
    "    test_inputs, test_targets = [x.to(device) for x in meta_test_batch[\"test\"]]\n",
    "    \n",
    "    cum_loss = torch.tensor(0., device=device)\n",
    "    accuracy = torch.tensor(0., device=device)\n",
    "    reg = torch.tensor(0., device=device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "        zip(train_inputs, train_targets, test_inputs, test_targets)):\n",
    "        for i in range(1):\n",
    "            sample_optimizer.zero_grad()\n",
    "            pred, kld = model(train_input, train_target, test_input)\n",
    "            loss = F.cross_entropy(pred, test_target)\n",
    "            loss.backward()\n",
    "            sample_optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            pred, kld = model(train_input, train_target, test_input)\n",
    "            loss = F.cross_entropy(pred, test_target)\n",
    "            cum_loss += loss\n",
    "            accuracy += torch.sum(pred.argmax(1) == test_target.cuda()) \n",
    "            reg += kld\n",
    "\n",
    "    tot_loss += cum_loss / batch_size\n",
    "    tot_acc += accuracy / (batch_size * 75)\n",
    "    tot_reg += reg / batch_size\n",
    "        \n",
    "tot_loss /= num_batches\n",
    "tot_acc /= num_batches\n",
    "tot_reg /= num_batches\n",
    "        \n",
    "print(\"loss = %f, test_kld = %f, meta_test_acc = %f, time = %.3f sec\" %(tot_loss, tot_reg, tot_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
